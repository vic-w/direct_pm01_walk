[1mdiff --git a/source/direct_pm01_walk/direct_pm01_walk/tasks/direct/direct_pm01_walk/direct_pm01_walk_env.py b/source/direct_pm01_walk/direct_pm01_walk/tasks/direct/direct_pm01_walk/direct_pm01_walk_env.py[m
[1mindex e672b48..8f7f958 100644[m
[1m--- a/source/direct_pm01_walk/direct_pm01_walk/tasks/direct/direct_pm01_walk/direct_pm01_walk_env.py[m
[1m+++ b/source/direct_pm01_walk/direct_pm01_walk/tasks/direct/direct_pm01_walk/direct_pm01_walk_env.py[m
[36m@@ -236,22 +236,22 @@[m [mclass DirectPm01WalkEnv(DirectRLEnv):[m
         print("joint_symmetry_penalty: %.3f \t weighted: %.3f" % (-joint_symmetry_penalty.mean().item(), -joint_symmetry_penalty.mean().item() * weight))[m
 [m
         left_leg_sum_penalty = joint_sum_l2(self, joint_names=["j00_hip_pitch_l", "j03_knee_pitch_l", "j04_ankle_pitch_l"])[m
[31m-        weight = 0.2[m
[32m+[m[32m        weight = 0.1[m
         reward -= left_leg_sum_penalty * weight[m
         print("left_leg_sum_penalty: %.3f \t weighted: %.3f" % (-left_leg_sum_penalty.mean().item(), -left_leg_sum_penalty.mean().item() * weight))[m
 [m
         left_leg_equal_penalty = joint_equal_l2(self, joint_name_a="j00_hip_pitch_l", joint_name_b="j04_ankle_pitch_l")[m
[31m-        weight = 0.2[m
[32m+[m[32m        weight = 0.1[m
         reward -= left_leg_equal_penalty * weight[m
         print("left_leg_equal_penalty: %.3f \t weighted: %.3f" % (-left_leg_equal_penalty.mean().item(), -left_leg_equal_penalty.mean().item() * weight))[m
 [m
         right_leg_sum_penalty = joint_sum_l2(self, joint_names=["j06_hip_pitch_r", "j09_knee_pitch_r", "j10_ankle_pitch_r"])[m
[31m-        weight = 0.2[m
[32m+[m[32m        weight = 0.1[m
         reward -= right_leg_sum_penalty * weight[m
         print("right_leg_sum_penalty: %.3f \t weighted: %.3f" % (-right_leg_sum_penalty.mean().item(), -right_leg_sum_penalty.mean().item() * weight))[m
 [m
         right_leg_equal_penalty = joint_equal_l2(self, joint_name_a="j06_hip_pitch_r", joint_name_b="j10_ankle_pitch_r")[m
[31m-        weight = 0.2[m
[32m+[m[32m        weight = 0.1[m
         reward -= right_leg_equal_penalty * weight[m
         print("right_leg_equal_penalty: %.3f \t weighted: %.3f" % (-right_leg_equal_penalty.mean().item(), -right_leg_equal_penalty.mean().item() * weight))[m
 [m
[1mdiff --git a/source/direct_pm01_walk/direct_pm01_walk/tasks/direct/direct_pm01_walk/rewards/rewards.py b/source/direct_pm01_walk/direct_pm01_walk/tasks/direct/direct_pm01_walk/rewards/rewards.py[m
[1mindex 8bed862..b51e5d8 100644[m
[1m--- a/source/direct_pm01_walk/direct_pm01_walk/tasks/direct/direct_pm01_walk/rewards/rewards.py[m
[1m+++ b/source/direct_pm01_walk/direct_pm01_walk/tasks/direct/direct_pm01_walk/rewards/rewards.py[m
[36m@@ -195,6 +195,7 @@[m [mdef get_gait_phase_reward(env):[m
 [m
     # å½“å‰è„šçš„ä¸–ç•Œåæ ‡é«˜åº¦[m
     zL, zR = body_pos[:, l_id, 2], body_pos[:, r_id, 2][m
[32m+[m[32m    print('zL:', zL[0].item(), ' zR:', zR[0].item())[m
 [m
     # å½“å‰æ­¥æ€ç›¸ä½ï¼ˆå‡è®¾éšæ—¶é—´çº¿æ€§å¢åŠ ï¼‰[m
     phase = env.gait_phase[m
[36m@@ -202,8 +203,8 @@[m [mdef get_gait_phase_reward(env):[m
 [m
     # ç†æƒ³çš„è„šé«˜åº¦æ›²çº¿ï¼šsin(phase) å¯¹åº”çš„ç›®æ ‡é«˜åº¦[m
     # å·¦è„šï¼šåœ¨ sin>0 æ—¶é«˜ï¼Œå³è„šç›¸å[m
[31m-    target_L = 0.1 + 0.1 * torch.clamp(phase_sin, min=0.0)   # æ­£åŠå‘¨æŠ¬é«˜åˆ° +0.2m[m
[31m-    target_R = 0.1 + 0.1 * torch.clamp(-phase_sin, min=0.0)  # è´ŸåŠå‘¨æŠ¬é«˜åˆ° +0.2m[m
[32m+[m[32m    target_L = 0.2 * torch.clamp(phase_sin, min=0.0)   # æ­£åŠå‘¨æŠ¬é«˜åˆ° +0.2m[m
[32m+[m[32m    target_R = 0.2 * torch.clamp(-phase_sin, min=0.0)  # è´ŸåŠå‘¨æŠ¬é«˜åˆ° +0.2m[m
 [m
     # å®é™…è„šé«˜åº¦ä¸ç›®æ ‡é«˜åº¦çš„åå·®[m
     err_L = (zL - target_L).pow(2)[m
